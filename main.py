import streamlit as st
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing, load_diabetes, load_wine, load_breast_cancer, fetch_openml, make_regression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.inspection import permutation_importance
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from mpl_toolkits.mplot3d import Axes3D


# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Educa√ß√£o Machine Learning",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://www.streamlit.io/community',
        'Report a bug': "https://github.com/LoowdY/educacao_machine_learning",
        'About': "# Aplicativo de An√°lise de Regress√£o\n"
                 "Este aplicativo foi desenvolvido para explorar modelos de regress√£o "
                 "usando conjuntos de dados √©ticos e t√©cnicas avan√ßadas de an√°lise."
    }
)

# # Fun√ß√£o para aplicar estilo CSS personalizado
# def aplicar_estilo():
#     st.markdown("""
#     <style>
#     .main {
#         background-color: #f0f2f6;
#     }
#     .stButton>button {
#         background-color: #4CAF50;
#         color: white;
#     }
#     .stSelectbox {
#         background-color: #e1e5eb;
#     }
#     </style>
#     """, unsafe_allow_html=True)

# Aplicar estilo personalizado
# aplicar_estilo()

# Fun√ß√£o para calcular RMSE
def raiz_erro_quadratico_medio(y_verdadeiro, y_previsto):
    return np.sqrt(mean_squared_error(y_verdadeiro, y_previsto))

# Fun√ß√£o para carregar os dados com cache
@st.cache_data
def carregar_dados(nome_conjunto_dados):
    if nome_conjunto_dados == "Habita√ß√£o na Calif√≥rnia":
        dados = fetch_california_housing()
        X = pd.DataFrame(dados.data, columns=dados.feature_names)
        y = pd.Series(dados.target, name='alvo')
        descricao = """
        Este conjunto de dados cont√©m informa√ß√µes sobre habita√ß√£o na Calif√≥rnia. 
        Ele inclui m√©tricas como renda m√©dia, idade da casa, n√∫mero m√©dio de c√¥modos, 
        entre outros. O objetivo √© prever o valor m√©dio das casas em um bloco (medido em centenas de milhares de d√≥lares).

        Caracter√≠sticas:
        - MedInc: renda mediana da popula√ß√£o do bloco
        - HouseAge: idade mediana das casas no bloco
        - AveRooms: n√∫mero m√©dio de c√¥modos por resid√™ncia
        - AveBedrms: n√∫mero m√©dio de quartos por resid√™ncia
        - Population: popula√ß√£o do bloco
        - AveOccup: n√∫mero m√©dio de ocupantes por resid√™ncia
        - Latitude: latitude do bloco
        - Longitude: longitude do bloco

        Alvo:
        - Valor m√©dio das casas para o bloco (em centenas de milhares de d√≥lares)
        """
    elif nome_conjunto_dados == "Diabetes":
        dados = load_diabetes()
        X = pd.DataFrame(dados.data, columns=dados.feature_names)
        y = pd.Series(dados.target, name='alvo')
        descricao = """
        Este conjunto de dados cont√©m informa√ß√µes sobre pacientes com diabetes. 
        Ele inclui v√°rias medidas fisiol√≥gicas e um indicador quantitativo de 
        progress√£o da doen√ßa um ano ap√≥s a linha de base.

        Caracter√≠sticas:
        - age: idade
        - sex: sexo
        - bmi: √≠ndice de massa corporal
        - bp: press√£o arterial m√©dia
        - s1-s6: seis medidas sangu√≠neas

        Alvo:
        - Medida quantitativa da progress√£o da doen√ßa um ano ap√≥s a linha de base
        """
    elif nome_conjunto_dados == "Vinho":
        dados = load_wine()
        X = pd.DataFrame(dados.data, columns=dados.feature_names)
        y = pd.Series(dados.target, name='alvo')
        descricao = """
        Este conjunto de dados cont√©m informa√ß√µes sobre diferentes tipos de vinho. 
        Ele inclui v√°rias medidas qu√≠micas que podem ser usadas para determinar 
        a origem do vinho.

        Caracter√≠sticas:
        - alcohol: teor alco√≥lico
        - malic_acid: √°cido m√°lico
        - ash: cinzas
        - alcalinity_of_ash: alcalinidade das cinzas
        - magnesium: magn√©sio
        - total_phenols: fen√≥is totais
        - flavanoids: flavonoides
        - nonflavanoid_phenols: fen√≥is n√£o flavonoides
        - proanthocyanins: proantocianinas
        - color_intensity: intensidade da cor
        - hue: tonalidade
        - od280/od315_of_diluted_wines: OD280/OD315 de vinhos dilu√≠dos
        - proline: prolina

        Alvo:
        - Classe do vinho (0, 1, 2)
        """
    elif nome_conjunto_dados == "C√¢ncer de Mama":
        dados = load_breast_cancer()
        X = pd.DataFrame(dados.data, columns=dados.feature_names)
        y = pd.Series(dados.target, name='alvo')
        descricao = """
        Este conjunto de dados cont√©m informa√ß√µes sobre caracter√≠sticas de c√©lulas 
        de c√¢ncer de mama. Ele pode ser usado para prever se um tumor √© maligno ou benigno.

        Caracter√≠sticas:
        - mean radius: raio m√©dio
        - mean texture: textura m√©dia
        - mean perimeter: per√≠metro m√©dio
        - mean area: √°rea m√©dia
        - mean smoothness: suavidade m√©dia
        ... (e outras caracter√≠sticas similares)

        Alvo:
        - Diagn√≥stico (0 = maligno, 1 = benigno)
        """
    else:  # Habita√ß√£o em Ames
        dados = fetch_openml(name="house_prices", as_frame=True)
        X = dados.data
        y = dados.target
        descricao = """
        Este conjunto de dados cont√©m informa√ß√µes detalhadas sobre casas em Ames, Iowa. 
        Ele inclui uma ampla variedade de caracter√≠sticas que podem influenciar o pre√ßo de venda.

        Caracter√≠sticas:
        - LotArea: Tamanho do lote em p√©s quadrados
        - OverallQual: Avalia√ß√£o geral do material e acabamento da casa
        - YearBuilt: Ano de constru√ß√£o original
        - TotalBsmtSF: √Årea total do por√£o em p√©s quadrados
        ... (e muitas outras caracter√≠sticas)

        Alvo:
        - SalePrice: Pre√ßo de venda da propriedade em d√≥lares
        """
    
    return X, y, descricao

# Fun√ß√µes de visualiza√ß√£o
def plotar_dispersao(X, y, caracteristica):
    fig = px.scatter(x=X[caracteristica], y=y, labels={'x': caracteristica, 'y': 'Alvo'})
    fig.update_layout(title=f"Rela√ß√£o entre {caracteristica} e Alvo")
    return fig

def plotar_importancia_caracteristicas(modelo, nomes_caracteristicas, X_teste, y_teste):
    if hasattr(modelo, 'feature_importances_'):
        importancias = pd.DataFrame({'caracteristica': nomes_caracteristicas, 'importancia': modelo.feature_importances_})
    else:
        resultado = permutation_importance(modelo, X_teste, y_teste, n_repeats=10, random_state=42)
        importancias = pd.DataFrame({'caracteristica': nomes_caracteristicas, 'importancia': resultado.importances_mean})
    
    importancias = importancias.sort_values('importancia', ascending=False)
    fig = px.bar(importancias, x='importancia', y='caracteristica', orientation='h',
                 title='Import√¢ncia das Caracter√≠sticas')
    return fig

def plotar_residuos(y_teste, y_previsto):
    residuos = y_teste - y_previsto
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=y_teste, y=residuos, mode='markers'))
    fig.update_layout(title='Gr√°fico de Res√≠duos',
                      xaxis_title='Valores Reais',
                      yaxis_title='Res√≠duos')
    return fig

# Fun√ß√µes para gerar gr√°ficos educativos
def plot_linear_regression():
    X, y = make_regression(n_samples=100, n_features=1, noise=20, random_state=42)
    model = LinearRegression()
    model.fit(X, y)
    
    fig, ax = plt.subplots()
    ax.scatter(X, y, alpha=0.5)
    ax.plot(X, model.predict(X), color='r')
    ax.set_title('Regress√£o Linear')
    ax.set_xlabel('X')
    ax.set_ylabel('y')
    return fig

def plot_decision_tree():
    X, y = make_regression(n_samples=100, n_features=1, noise=20, random_state=42)
    model = DecisionTreeRegressor(max_depth=3)
    model.fit(X, y)
    
    fig, ax = plt.subplots(figsize=(12, 8))
    plot_tree(model, filled=True, feature_names=['X'], ax=ax)
    ax.set_title('√Årvore de Decis√£o')
    return fig

def plot_random_forest():
    X, y = make_regression(n_samples=100, n_features=1, noise=20, random_state=42)
    model = RandomForestRegressor(n_estimators=10, max_depth=3, random_state=42)
    model.fit(X, y)
    
    fig, ax = plt.subplots()
    ax.scatter(X, y, alpha=0.5)
    x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
    y_pred = model.predict(x_range)
    ax.plot(x_range, y_pred, color='r', label='Random Forest')
    ax.set_title('Random Forest')
    ax.set_xlabel('X')
    ax.set_ylabel('y')
    ax.legend()
    return fig

def plot_svr():
    X, y = make_regression(n_samples=100, n_features=1, noise=20, random_state=42)
    model = SVR(kernel='rbf')
    model.fit(X, y)
    
    fig, ax = plt.subplots()
    ax.scatter(X, y, alpha=0.5)
    x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
    y_pred = model.predict(x_range)
    ax.plot(x_range, y_pred, color='r', label='SVR')
    ax.set_title('Support Vector Regression')
    ax.set_xlabel('X')
    ax.set_ylabel('y')
    ax.legend()
    return fig

def plot_knn():
    X, y = make_regression(n_samples=100, n_features=1, noise=20, random_state=42)
    model = KNeighborsRegressor(n_neighbors=5)
    model.fit(X, y)
    
    fig, ax = plt.subplots()
    ax.scatter(X, y, alpha=0.5)
    x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
    y_pred = model.predict(x_range)
    ax.plot(x_range, y_pred, color='r', label='KNN')
    ax.set_title('K-Nearest Neighbors')
    ax.set_xlabel('X')
    ax.set_ylabel('y')
    ax.legend()
    return fig

# T√≠tulo da aplica√ß√£o
st.title("üìä Aplica√ß√£o Avan√ßada de Modelos de Regress√£o √âticos")
st.latex(r'''
\text{Esta aplica√ß√£o permite explorar diferentes conjuntos de dados √©ticos e modelos de regress√£o de forma interativa.} \\
\text{Voc√™ pode selecionar o conjunto de dados, o modelo, seus par√¢metros e a vari√°vel resposta.}
''')

# Barra lateral: Sele√ß√£o de conjunto de dados
st.sidebar.title("üõ†Ô∏è Configura√ß√µes")
nome_conjunto_dados = st.sidebar.selectbox(
    "Escolha o Conjunto de Dados", 
    ("Habita√ß√£o na Calif√≥rnia", "Diabetes", "Vinho", "C√¢ncer de Mama", "Habita√ß√£o em Ames")
)

# Carregar os dados
X, y, descricao_conjunto_dados = carregar_dados(nome_conjunto_dados)

# Exibir descri√ß√£o do conjunto de dados
with st.expander("üìå Descri√ß√£o do Conjunto de Dados"):
    st.text(descricao_conjunto_dados)

# Sele√ß√£o da vari√°vel resposta
if nome_conjunto_dados != "Habita√ß√£o em Ames":
    variavel_alvo = st.sidebar.selectbox("Escolha a vari√°vel resposta", X.columns.tolist() + ['alvo'])
    if variavel_alvo != 'alvo':
        y = X[variavel_alvo]
        X = X.drop(columns=[variavel_alvo])
else:
    st.sidebar.info("Para o conjunto de dados Habita√ß√£o em Ames, a vari√°vel resposta √© fixa como 'price'.")

# Exibir uma amostra dos dados
st.subheader("üìã Amostra dos Dados")
st.dataframe(pd.concat([X, y], axis=1).head())

# Visualiza√ß√£o explorat√≥ria
st.subheader("üîç Visualiza√ß√£o Explorat√≥ria")
col1, col2 = st.columns(2)
with col1:
    caracteristica_para_plotar = st.selectbox("Selecione uma caracter√≠stica para visualizar:", X.columns)
    st.plotly_chart(plotar_dispersao(X, y, caracteristica_para_plotar), use_container_width=True)
with col2:
    st.write("### Matriz de Correla√ß√£o")
    correlacao = pd.concat([X, y], axis=1).corr()
    fig = px.imshow(correlacao, text_auto=True, aspect="auto")
    st.plotly_chart(fig, use_container_width=True)

# Dividir os dados em treino e teste
tamanho_teste = st.sidebar.slider("Tamanho do Conjunto de Teste (%)", 10, 50, 20) / 100
X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=tamanho_teste, random_state=42)

# Normaliza√ß√£o dos dados
escalonador = StandardScaler()
X_treino_escalonado = escalonador.fit_transform(X_treino)
X_teste_escalonado = escalonador.transform(X_teste)

# Barra lateral: Sele√ß√£o de modelo
nome_modelo = st.sidebar.selectbox("Escolha o Modelo", 
                                  ("Floresta Aleat√≥ria", "Aumento de Gradiente", "XGBoost", "LightGBM",
                                   "Regress√£o Linear", "Ridge", "Lasso", "Rede El√°stica",
                                   "√Årvore de Decis√£o", "SVR", "K-Vizinhos"))

# Definir os hiperpar√¢metros do modelo
if nome_modelo == "Floresta Aleat√≥ria":
    n_estimadores = st.sidebar.slider("N√∫mero de √Årvores", 10, 200, 100)
    profundidade_maxima = st.sidebar.slider("Profundidade M√°xima", 1, 20, 10)
    amostras_minimas_divisao = st.sidebar.slider("M√≠nimo de Amostras para Divis√£o", 2, 10, 2)
    modelo = RandomForestRegressor(n_estimators=n_estimadores, max_depth=profundidade_maxima, 
                                  min_samples_split=amostras_minimas_divisao, random_state=42)
elif nome_modelo == "Aumento de Gradiente":
    n_estimadores = st.sidebar.slider("N√∫mero de Estimadores", 50, 500, 100)
    taxa_aprendizagem = st.sidebar.slider("Taxa de Aprendizagem", 0.01, 0.3, 0.1)
    profundidade_maxima = st.sidebar.slider("Profundidade M√°xima", 1, 10, 3)
    modelo = GradientBoostingRegressor(n_estimators=n_estimadores, learning_rate=taxa_aprendizagem, 
                                      max_depth=profundidade_maxima, random_state=42)
elif nome_modelo == "XGBoost":
    n_estimadores = st.sidebar.slider("N√∫mero de Estimadores", 50, 500, 100)
    taxa_aprendizagem = st.sidebar.slider("Taxa de Aprendizagem", 0.01, 0.3, 0.1)
    profundidade_maxima = st.sidebar.slider("Profundidade M√°xima", 1, 10, 3)
    modelo = XGBRegressor(n_estimators=n_estimadores, learning_rate=taxa_aprendizagem, 
                         max_depth=profundidade_maxima, random_state=42)
elif nome_modelo == "LightGBM":
    n_estimadores = st.sidebar.slider("N√∫mero de Estimadores", 50, 500, 100)
    taxa_aprendizagem = st.sidebar.slider("Taxa de Aprendizagem", 0.01, 0.3, 0.1)
    profundidade_maxima = st.sidebar.slider("Profundidade M√°xima", 1, 10, 3)
    modelo = LGBMRegressor(n_estimators=n_estimadores, learning_rate=taxa_aprendizagem, 
                          max_depth=profundidade_maxima, random_state=42)
elif nome_modelo == "Regress√£o Linear":
    modelo = LinearRegression()
elif nome_modelo == "Ridge":
    alfa = st.sidebar.slider("Alfa", 0.1, 10.0, 1.0)
    modelo = Ridge(alpha=alfa, random_state=42)
elif nome_modelo == "Lasso":
    alfa = st.sidebar.slider("Alfa", 0.1, 10.0, 1.0)
    modelo = Lasso(alpha=alfa, random_state=42)
elif nome_modelo == "Rede El√°stica":
    alfa = st.sidebar.slider("Alfa", 0.1, 10.0, 1.0)
    razao_l1 = st.sidebar.slider("Raz√£o L1", 0.0, 1.0, 0.5)
    modelo = ElasticNet(alpha=alfa, l1_ratio=razao_l1, random_state=42)
elif nome_modelo == "√Årvore de Decis√£o":
    profundidade_maxima = st.sidebar.slider("Profundidade M√°xima", 1, 20, 5)
    amostras_minimas_divisao = st.sidebar.slider("M√≠nimo de Amostras para Divis√£o", 2, 10, 2)
    modelo = DecisionTreeRegressor(max_depth=profundidade_maxima, min_samples_split=amostras_minimas_divisao, random_state=42)
elif nome_modelo == "SVR":
    C = st.sidebar.slider("C", 0.1, 10.0, 1.0)
    epsilon = st.sidebar.slider("Epsilon", 0.01, 1.0, 0.1)
    modelo = SVR(C=C, epsilon=epsilon)
else:  # K-Vizinhos
    n_vizinhos = st.sidebar.slider("N√∫mero de Vizinhos", 1, 20, 5)
    modelo = KNeighborsRegressor(n_neighbors=n_vizinhos)

# Treinar o modelo
modelo.fit(X_treino_escalonado, y_treino)
y_previsto = modelo.predict(X_teste_escalonado)

# Painel de M√©tricas
st.subheader("üìä Painel de M√©tricas")
col1, col2, col3, col4 = st.columns(4)
col1.metric("EAM", f"{mean_absolute_error(y_teste, y_previsto):.4f}")
col2.metric("EQM", f"{mean_squared_error(y_teste, y_previsto):.4f}")
col3.metric("REQM", f"{raiz_erro_quadratico_medio(y_teste, y_previsto):.4f}")
col4.metric("R¬≤", f"{r2_score(y_teste, y_previsto):.4f}")

# Gr√°fico de compara√ß√£o entre valores reais e previstos
st.subheader("üìà Compara√ß√£o: Valores Reais vs. Previstos")
fig = px.scatter(x=y_teste, y=y_previsto, labels={'x': 'Valores Reais', 'y': 'Valores Previstos'})
fig.add_trace(go.Scatter(x=[y_teste.min(), y_teste.max()], y=[y_teste.min(), y_teste.max()],
                         mode='lines', name='Linha de Refer√™ncia'))
st.plotly_chart(fig, use_container_width=True)

# Gr√°fico de import√¢ncia das caracter√≠sticas
st.subheader("üèÜ Import√¢ncia das Caracter√≠sticas")
st.plotly_chart(plotar_importancia_caracteristicas(modelo, X.columns, X_teste_escalonado, y_teste), use_container_width=True)

# Gr√°fico de res√≠duos
st.subheader("üéØ An√°lise de Res√≠duos")
st.plotly_chart(plotar_residuos(y_teste, y_previsto), use_container_width=True)

# Se√ß√£o Educativa Expandida
st.subheader("üìö Se√ß√£o Educativa")

# Explica√ß√£o das M√©tricas
with st.expander("Entenda as M√©tricas de Avalia√ß√£o"):
    st.latex(r'''
    \textbf{Erro Absoluto M√©dio (EAM):} \\
    EAM = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| \\
    \text{Interpreta√ß√£o: Quanto menor, melhor. Indica a magnitude m√©dia do erro.} \\
    
    \textbf{Erro Quadr√°tico M√©dio (EQM):} \\
    EQM = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \\
    \text{Interpreta√ß√£o: Penaliza erros maiores. Quanto menor, melhor.} \\
    
    \textbf{Raiz do Erro Quadr√°tico M√©dio (REQM):} \\
    REQM = \sqrt{EQM} \\
    \text{Interpreta√ß√£o: Na mesma unidade da vari√°vel alvo. Menor √© melhor.} \\
    
    \textbf{Coeficiente de Determina√ß√£o (R¬≤):} \\
    R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} \\
    \text{Interpreta√ß√£o: Varia de 0 a 1. Quanto mais pr√≥ximo de 1, melhor o modelo explica os dados.}
    ''')

# Explica√ß√£o dos Algoritmos com Gr√°ficos
with st.expander("Entenda os Algoritmos de Regress√£o"):
    st.markdown("""
    ### Algoritmos de Regress√£o

    1. **Regress√£o Linear**
       - **O que √©**: Modelo que assume uma rela√ß√£o linear entre as vari√°veis independentes e a vari√°vel dependente.
       - **Como funciona**: Encontra a melhor linha reta que minimiza a soma dos quadrados dos res√≠duos.
    """)
    st.pyplot(plot_linear_regression())

    st.markdown("""
    2. **Floresta Aleat√≥ria (Random Forest)**
       - **O que √©**: Ensemble de √°rvores de decis√£o.
       - **Como funciona**: Cria m√∫ltiplas √°rvores de decis√£o e combina suas previs√µes.
    """)
    st.pyplot(plot_random_forest())

    st.markdown("""
    3. **√Årvore de Decis√£o**
       - **O que √©**: Modelo que divide os dados em subgrupos baseados em regras de decis√£o.
       - **Como funciona**: Cria uma estrutura de √°rvore com n√≥s de decis√£o e folhas de previs√£o.
    """)
    st.pyplot(plot_decision_tree())

    st.markdown("""
    4. **SVR (Support Vector Regression)**
       - **O que √©**: Extens√£o do SVM para problemas de regress√£o.
       - **Como funciona**: Busca encontrar um hiperplano que melhor se ajusta aos dados dentro de uma margem de toler√¢ncia.
    """)
    st.pyplot(plot_svr())

    st.markdown("""
    5. **K-Vizinhos (K-Nearest Neighbors)**
       - **O que √©**: M√©todo baseado em inst√¢ncia que usa os vizinhos mais pr√≥ximos para previs√£o.
       - **Como funciona**: Prev√™ baseado na m√©dia dos valores dos K vizinhos mais pr√≥ximos.
    """)
    st.pyplot(plot_knn())

# Dicas para Interpreta√ß√£o dos Gr√°ficos
with st.expander("Dicas para Interpreta√ß√£o dos Gr√°ficos"):
    st.markdown("""
    1. **Gr√°fico de Dispers√£o (Caracter√≠stica vs. Alvo):**
       - Ajuda a identificar rela√ß√µes lineares ou n√£o lineares entre caracter√≠sticas e o alvo.
       - Padr√µes claros indicam forte rela√ß√£o; dispers√£o aleat√≥ria sugere fraca rela√ß√£o.

    2. **Matriz de Correla√ß√£o:**
       - Cores mais intensas (vermelhas ou azuis) indicam correla√ß√µes mais fortes.
       - Correla√ß√µes pr√≥ximas a 1 ou -1 sugerem forte rela√ß√£o linear.

    3. **Gr√°fico de Valores Reais vs. Previstos:**
       - Pontos pr√≥ximos √† linha diagonal indicam previs√µes precisas.
       - Dispers√£o uniforme em torno da linha √© ideal.

    4. **Import√¢ncia das Caracter√≠sticas:**
       - Barras mais longas indicam caracter√≠sticas mais importantes para o modelo.
       - √ötil para sele√ß√£o de caracter√≠sticas e entendimento do modelo.

    5. **Gr√°fico de Res√≠duos:**
       - Idealmente, os res√≠duos devem ser distribu√≠dos aleatoriamente em torno de zero.
       - Padr√µes nos res√≠duos podem indicar que o modelo n√£o capturou alguma informa√ß√£o importante.
    """)

# Guia de Sele√ß√£o de Modelos
with st.expander("Guia de Sele√ß√£o de Modelos"):
    st.markdown("""
    ### Como Escolher o Modelo Adequado

    1. **Para dados lineares e interpretabilidade:**
       - Regress√£o Linear, Ridge, Lasso

    2. **Para dados complexos e n√£o-lineares:**
       - Floresta Aleat√≥ria, Gradient Boosting, XGBoost, LightGBM

    3. **Para datasets pequenos:**
       - Regress√£o Linear, SVR, K-Vizinhos

    4. **Para grandes volumes de dados:**
       - Floresta Aleat√≥ria, XGBoost, LightGBM

    5. **Quando a interpretabilidade √© crucial:**
       - √Årvore de Decis√£o, Regress√£o Linear

    6. **Para lidar com multicolinearidade:**
       - Ridge, Lasso, Rede El√°stica

    7. **Para sele√ß√£o autom√°tica de features:**
       - Lasso, Floresta Aleat√≥ria (import√¢ncia das features)

    8. **Quando o tempo de treinamento √© limitado:**
       - K-Vizinhos, √Årvore de Decis√£o

    Lembre-se: A escolha do modelo ideal geralmente envolve experimenta√ß√£o e compara√ß√£o de desempenho em seus dados espec√≠ficos.
    """)

# Se√ß√£o de Previs√£o
st.subheader("üîÆ Fa√ßa uma Previs√£o")
st.write("Use esta se√ß√£o para fazer previs√µes com o modelo treinado.")

# Criar campos de entrada para cada caracter√≠stica
valores_entrada = {}
for coluna in X.columns:
    valores_entrada[coluna] = st.number_input(f"Insira o valor para {coluna}", value=X[coluna].mean())

# Bot√£o para fazer a previs√£o
if st.button("Fazer Previs√£o"):
    # Preparar os dados de entrada
    entrada_previsao = pd.DataFrame([valores_entrada])
    entrada_previsao_escalonada = escalonador.transform(entrada_previsao)
    
    # Fazer a previs√£o
    previsao = modelo.predict(entrada_previsao_escalonada)
    
    # Exibir o resultado
    st.success(f"A previs√£o do modelo √©: {previsao[0]:.2f}")

# Se√ß√£o de Compara√ß√£o de Modelos
st.subheader("üèÜ Compara√ß√£o de Modelos")
st.write("Compare o desempenho de diferentes modelos.")

# Lista de modelos para compara√ß√£o
modelos_comparacao = {
    "Floresta Aleat√≥ria": RandomForestRegressor(n_estimators=100, random_state=42),
    "Aumento de Gradiente": GradientBoostingRegressor(n_estimators=100, random_state=42),
    "Regress√£o Linear": LinearRegression(),
    "SVR": SVR(),
    "K-Vizinhos": KNeighborsRegressor(n_neighbors=5)
}

# Treinar e avaliar cada modelo
resultados_comparacao = []
for nome_modelo, modelo in modelos_comparacao.items():
    modelo.fit(X_treino_escalonado, y_treino)
    y_previsto = modelo.predict(X_teste_escalonado)
    mse = mean_squared_error(y_teste, y_previsto)
    r2 = r2_score(y_teste, y_previsto)
    resultados_comparacao.append({"Modelo": nome_modelo, "EQM": mse, "R¬≤": r2})

# Exibir resultados da compara√ß√£o
df_comparacao = pd.DataFrame(resultados_comparacao)
st.dataframe(df_comparacao)

# Gr√°fico de barras para compara√ß√£o visual
fig_comparacao = px.bar(df_comparacao, x="Modelo", y=["EQM", "R¬≤"], barmode="group",
                        title="Compara√ß√£o de Desempenho dos Modelos")
st.plotly_chart(fig_comparacao, use_container_width=True)

# Se√ß√£o de Dicas e Melhores Pr√°ticas
st.subheader("üí° Dicas e Melhores Pr√°ticas")
st.write("""
1. **Prepara√ß√£o dos Dados:** Sempre verifique a qualidade dos seus dados. Trate valores ausentes e outliers.
2. **Sele√ß√£o de Caracter√≠sticas:** Use t√©cnicas como correla√ß√£o e import√¢ncia de caracter√≠sticas para selecionar as melhores vari√°veis.
3. **Valida√ß√£o Cruzada:** Para uma avalia√ß√£o mais robusta, considere usar valida√ß√£o cruzada em vez de uma √∫nica divis√£o treino/teste.
4. **Ajuste de Hiperpar√¢metros:** Experimente diferentes configura√ß√µes de hiperpar√¢metros para otimizar o desempenho do modelo.
5. **Interpretabilidade:** Considere o equil√≠brio entre desempenho e interpretabilidade ao escolher um modelo.
6. **Atualiza√ß√£o do Modelo:** Reavalie e atualize seu modelo regularmente com novos dados para manter sua precis√£o.
""")

# Rodap√©
st.markdown("---")
st.markdown("Desenvolvido com ‚ù§Ô∏è usando Streamlit | Criado para fins educativos")

# Bot√£o para resetar a aplica√ß√£o
if st.sidebar.button("üîÑ Resetar Aplica√ß√£o"):
    st.rerun()

# Informa√ß√µes Adicionais
st.sidebar.markdown("---")
st.sidebar.subheader("‚ÑπÔ∏è Informa√ß√µes Adicionais")
st.sidebar.info("""
Este aplicativo foi desenvolvido para fins educacionais e de demonstra√ß√£o.
Ele utiliza conjuntos de dados √©ticos e t√©cnicas de aprendizado de m√°quina
para explorar diferentes modelos de regress√£o.

**Vers√£o:** 1.0
**√öltima atualiza√ß√£o:** 2023-06-01
""")

# Feedback do usu√°rio
st.sidebar.markdown("---")
st.sidebar.subheader("üìù Feedback")
feedback = st.sidebar.text_area("Deixe seu feedback ou sugest√µes:")
if st.sidebar.button("Enviar Feedback"):
    # Aqui voc√™ pode implementar a l√≥gica para salvar o feedback
    st.sidebar.success("Obrigado pelo seu feedback!")

# Se√ß√£o de Recursos Adicionais
st.markdown("---")
st.subheader("üìö Recursos Adicionais")
st.markdown("""
Para aprender mais sobre regress√£o e ci√™ncia de dados, confira estes recursos:

1. [Curso de Machine Learning do Coursera](https://www.coursera.org/learn/machine-learning)
2. [Documenta√ß√£o do Scikit-learn](https://scikit-learn.org/stable/documentation.html)
3. [Livro: "Hands-On Machine Learning with Scikit-Learn and TensorFlow"](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
4. [Kaggle: Competi√ß√µes e datasets de Machine Learning](https://www.kaggle.com/)
5. [Towards Data Science - Medium](https://towardsdatascience.com/)
""")

# Poss√≠veis Melhorias Futuras
st.markdown("---")
st.subheader("üöÄ Poss√≠veis Melhorias Futuras")
st.markdown("""
1. Implementar valida√ß√£o cruzada para uma avalia√ß√£o mais robusta dos modelos.
2. Adicionar mais t√©cnicas de pr√©-processamento de dados, como tratamento de outliers e codifica√ß√£o de vari√°veis categ√≥ricas.
3. Incorporar t√©cnicas de sele√ß√£o de caracter√≠sticas autom√°ticas.
4. Implementar otimiza√ß√£o de hiperpar√¢metros usando t√©cnicas como Grid Search ou Random Search.
5. Adicionar mais visualiza√ß√µes interativas para explora√ß√£o de dados.
6. Permitir o upload de datasets personalizados pelos usu√°rios.
7. Implementar funcionalidades de exporta√ß√£o de modelos treinados.
8. Adicionar mais algoritmos de regress√£o avan√ßados, como redes neurais.
""")

# Aviso Legal
st.markdown("---")
st.subheader("‚öñÔ∏è Aviso Legal")
st.markdown("""
Este aplicativo √© fornecido apenas para fins educacionais e de demonstra√ß√£o. 
N√£o deve ser usado para tomada de decis√µes em ambientes de produ√ß√£o sem uma 
valida√ß√£o adequada. Os autores n√£o se responsabilizam por quaisquer consequ√™ncias 
decorrentes do uso deste aplicativo.
""")

# Cr√©ditos e Agradecimentos
st.markdown("---")
st.subheader("üôè Cr√©ditos e Agradecimentos")
st.markdown("""
- Desenvolvido por: Jo√£o Renan Lopes E Carlos Egger
- Bibliotecas utilizadas: Streamlit, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, Plotly
- Agradecimentos especiais √† comunidade de c√≥digo aberto e aos contribuidores das bibliotecas utilizadas bem como ao professor Pedro Girotto.
""")

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center;">
    <p>Desenvolvido com ‚ù§Ô∏è usando Streamlit | Desenvolvedores: Jo√£o Renan Lopes E Carlos Egger | Professor: pedro Girotto ;)
</div>
""", unsafe_allow_html=True)
